{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# from PyPDF2 import PdfReader\n",
    "# from collections import Counter\n",
    "# import re\n",
    "# import os\n",
    "# import pandas as pd\n",
    "\n",
    "# def extract_sections(pdf_path, sections_of_interest):\n",
    "#     \"\"\"\n",
    "#     Extract specific sections (e.g., Abstract, Introduction) from a PDF.\n",
    "\n",
    "#     Args:\n",
    "#         pdf_path (str): Path to the PDF file.\n",
    "#         sections_of_interest (list of str): List of section titles to extract.\n",
    "\n",
    "#     Returns:\n",
    "#         dict: A dictionary with section titles as keys and their content as values.\n",
    "#     \"\"\"\n",
    "#     reader = PdfReader(pdf_path)\n",
    "#     section_texts = {section: \"\" for section in sections_of_interest}\n",
    "\n",
    "#     current_section = None\n",
    "#     for page in reader.pages:\n",
    "#         text = page.extract_text()\n",
    "#         lines = text.split(\"\\n\")\n",
    "#         for line in lines:\n",
    "#             line_clean = line.strip()\n",
    "#             if line_clean in sections_of_interest:\n",
    "#                 current_section = line_clean\n",
    "#             elif current_section and line_clean:\n",
    "#                 section_texts[current_section] += \" \" + line_clean\n",
    "\n",
    "#     return section_texts\n",
    "\n",
    "# def count_keywords(section_texts, keywords):\n",
    "#     \"\"\"\n",
    "#     Count occurrences of keywords in specified sections.\n",
    "\n",
    "#     Args:\n",
    "#         section_texts (dict): Dictionary with section titles as keys and their content as values.\n",
    "#         keywords (list of str): List of keywords to search for.\n",
    "\n",
    "#     Returns:\n",
    "#         dict: A dictionary with keywords as keys and their counts as values.\n",
    "#     \"\"\"\n",
    "#     keyword_counts = {key: 0 for key in keywords}\n",
    "#     for section, text in section_texts.items():\n",
    "#         word_counter = Counter(text.lower().split())  # Use a Counter to avoid overcounting phrases\n",
    "#         for keyword in keywords:\n",
    "#             keyword_counts[keyword] += word_counter[keyword.lower()]\n",
    "\n",
    "#     return keyword_counts\n",
    "\n",
    "# def find_sentences_with_keyword(section_texts, keyword):\n",
    "#     \"\"\"\n",
    "#     Find sentences containing a specific keyword in the sections.\n",
    "\n",
    "#     Args:\n",
    "#         section_texts (dict): Dictionary with section titles as keys and their content as values.\n",
    "#         keyword (str): Keyword to search for.\n",
    "\n",
    "#     Returns:\n",
    "#         list: List of sentences containing the keyword.\n",
    "#     \"\"\"\n",
    "#     sentences_with_keyword = []\n",
    "#     for section, text in section_texts.items():\n",
    "#         sentences = re.split(r'(?<!\\w\\.\\w.)(?<![A-Z][a-z]\\.)(?<=\\.|\\?)\\s', text)\n",
    "#         for sentence in sentences:\n",
    "#             if keyword.lower() in sentence.lower():\n",
    "#                 sentences_with_keyword.append(sentence.strip())\n",
    "#     return sentences_with_keyword\n",
    "\n",
    "# def process_papers(folder_path, sections_of_interest, keywords):\n",
    "#     \"\"\"\n",
    "#     Process all papers in a folder, count keywords, and compile results into a DataFrame.\n",
    "\n",
    "#     Args:\n",
    "#         folder_path (str): Path to the folder containing PDF files.\n",
    "#         sections_of_interest (list of str): List of section titles to extract.\n",
    "#         keywords (list of str): List of keywords to search for.\n",
    "\n",
    "#     Returns:\n",
    "#         pd.DataFrame: DataFrame containing paper names and keyword counts.\n",
    "#     \"\"\"\n",
    "#     results = []\n",
    "\n",
    "#     for filename in os.listdir(folder_path):\n",
    "#         if filename.endswith(\".pdf\"):\n",
    "#             pdf_path = os.path.join(folder_path, filename)\n",
    "#             section_texts = extract_sections(pdf_path, sections_of_interest)\n",
    "#             keyword_counts = count_keywords(section_texts, keywords)\n",
    "#             results.append([filename] + [keyword_counts.get(keyword, 0) for keyword in keywords])\n",
    "\n",
    "#     columns = [\"Paper Name\"] + keywords\n",
    "#     return pd.DataFrame(results, columns=columns)\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     # Folder containing PDF files\n",
    "#     #folder_path = \"Paper Neurips\"\n",
    "\n",
    "#     # Define sections of interest\n",
    "#     sections_of_interest = [\"Abstract\", \"Introduction\", \"Discussion\", \"Conclusion\"]\n",
    "\n",
    "#     # Define keywords to search for\n",
    "#     keywords = [\n",
    "#         \"Classification\", \"Prediction\", \"Generation\", \"Understanding\", \"Defenses\", \"Transparency\", \"Novelty\", \"Simplicity\", \"Generalization\", \"Flexibility/Extensibility\", \"Robustness\", \n",
    "#         \"Realistic output\", \"Formal description/analysis\", \"Theoretical guarantees\", \"Approximation\", \"Quantitative evidence (e.g. experiments)\", \"Qualitative evidence (e.g. examples)\", \n",
    "#         \"Scientific methodology\", \"Controllability (of model owner)\", \"Human-like mechanism\", \"Low cost\", \"Large scale\", \"Promising\", \"Generality\", \"Principled\", \"Exactness\", \"Preciseness\", \n",
    "#         \"Concreteness\", \"Automatic\", \"Performance\", \"Accuracy\", \"Avoiding train/test discrepancy\", \"State-of-the-art\", \"Efficiency\", \"Reduced training time\", \"Memory efficiency\", \n",
    "#         \"Data efficiency\", \"Label efficiency\", \"Energy efficiency\", \"Effectiveness\", \"Successful\", \"Building on classic work\", \"Building on recent work\", \"Unifying ideas\", \n",
    "#         \"integrating components\", \"Identifying limitations\", \"Critique\", \"Understanding\", \"Improvement\", \"Progress\", \"Used in practice\", \"Reproducibility\", \"Easy to implement\", \n",
    "#         \"Requires few resources\", \"Parallelizability\", \"distributed\", \"Facilitating use\", \"Scales up\", \"Applies to real world\", \"Learning from humans\", \"Practical\", \"Useful\", \"Interpretable\", \n",
    "#         \"Transparent\", \"Privacy\", \"Fairness\", \"Not socially biased\", \"User influence\", \"Collective influence\", \"Deferral to humans\", \"Critiqability\", \"Beneficence\", \"Non-maleficence\", \"Justice\", \n",
    "#         \"Respect for Persons\", \"Autonomy\", \"Explicability\", \"Respect for Law and public interest\", \"Security\", \"Easy to work with\", \"Realistic world model\", \"Fast\"\n",
    "#     ]\n",
    "\n",
    "#     # Process all papers and create a DataFrame\n",
    "#     keyword_matrix_neurips = process_papers(\"Paper Neurips\", sections_of_interest, keywords)\n",
    "#     keyword_matrix_icml = process_papers(\"Paper ICML\", sections_of_interest, keywords)\n",
    "\n",
    "#     # Save the results to a CSV file\n",
    "#     keyword_matrix_neurips.to_csv(\"keyword_counts_neurips.csv\", index=False)\n",
    "#     print(f\"Keyword counts saved to keyword_counts_neurips.csv\")\n",
    "\n",
    "#     keyword_matrix_icml.to_csv(\"keyword_counts_icml.csv\", index=False)\n",
    "#     print(f\"Keyword counts saved to keyword_counts_icml.csv\")\n",
    "\n",
    "#     # Search for sentences containing a specific keyword\n",
    "#     # keyword_to_search = input(\"Enter a keyword to search for sentences: \")\n",
    "#     # for filename in os.listdir(folder_path):\n",
    "#     #     if filename.endswith(\".pdf\"):\n",
    "#     #         pdf_path = os.path.join(folder_path, filename)\n",
    "#     #         section_texts = extract_sections(pdf_path, sections_of_interest)\n",
    "#     #         sentences = find_sentences_with_keyword(section_texts, keyword_to_search)\n",
    "#     #         if sentences:\n",
    "#     #             print(f\"\\nSentences containing '{keyword_to_search}' in {filename}:\")\n",
    "#     #             for sentence in sentences:\n",
    "#     #                 print(f\"- {sentence}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
