{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyword counts saved to keyword_counts_neurips.csv\n",
      "Keyword counts saved to keyword_counts_icml.csv\n"
     ]
    }
   ],
   "source": [
    "from PyPDF2 import PdfReader\n",
    "from collections import Counter\n",
    "import re\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def extract_sections(pdf_path, sections_of_interest):\n",
    "    \"\"\"\n",
    "    Extract specific sections (e.g., Abstract, Introduction) from a PDF.\n",
    "    \"\"\"\n",
    "    reader = PdfReader(pdf_path)\n",
    "    section_texts = {section: \"\" for section in sections_of_interest}\n",
    "    \n",
    "    current_section = None\n",
    "    for page in reader.pages:\n",
    "        text = page.extract_text()\n",
    "        if text:\n",
    "            # Ensure text is properly encoded and cleaned\n",
    "            text = text.encode(\"utf-8\", errors=\"ignore\").decode(\"utf-8\")\n",
    "            lines = text.split(\"\\n\")\n",
    "            for line in lines:\n",
    "                line_clean = line.strip()\n",
    "                if line_clean in sections_of_interest:\n",
    "                    current_section = line_clean\n",
    "                elif current_section and line_clean:\n",
    "                    section_texts[current_section] += \" \" + line_clean\n",
    "    \n",
    "    return section_texts\n",
    "\n",
    "\n",
    "def count_keywords(section_texts, keywords, keyword_list):\n",
    "    \"\"\"\n",
    "    Count occurrences of keyword variations in specified sections.\n",
    "    \"\"\"\n",
    "    keyword_counts = {key[0]: 0 for key in keywords}  # Initialize counts for primary terms\n",
    "    keyword_sentences = {key[0]: [] for key in keywords}  # Store sentences with occurrences\n",
    "    \n",
    "    for section, text in section_texts.items():\n",
    "        sentences = re.split(r'(?<!\\w\\.\\w.)(?<![A-Z][a-z]\\.)(?<=\\.|\\?)\\s', text)\n",
    "        for keyword_group in keywords:\n",
    "            main_keyword = keyword_group[0]\n",
    "            variations = keyword_group\n",
    "            for sentence in sentences:\n",
    "                for variation in variations:\n",
    "                    if variation.lower() in sentence.lower():\n",
    "                        keyword_counts[main_keyword] += 1\n",
    "                        keyword_sentences[main_keyword].append(sentence.strip())\n",
    "    \n",
    "    return keyword_counts, keyword_sentences\n",
    "\n",
    "def process_papers(folder_path, sections_of_interest, keywords):\n",
    "    \"\"\"\n",
    "    Process all papers in a folder, count keywords, and compile results into a DataFrame.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    keyword_list = [k[0] for k in keywords]\n",
    "    sentence_results = {key[0]: [] for key in keywords}\n",
    "    \n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(\".pdf\"):\n",
    "            pdf_path = os.path.join(folder_path, filename)\n",
    "            section_texts = extract_sections(pdf_path, sections_of_interest)\n",
    "            keyword_counts, keyword_sentences = count_keywords(section_texts, keywords, keyword_list)\n",
    "            results.append([filename] + [keyword_counts.get(keyword, 0) for keyword in keyword_list])\n",
    "            for key in keyword_sentences:\n",
    "                sentence_results[key].extend(keyword_sentences[key])\n",
    "    \n",
    "    columns = [\"Paper Name\"] + keyword_list\n",
    "    df = pd.DataFrame(results, columns=columns)\n",
    "    \n",
    "    return df, sentence_results\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Define sections of interest\n",
    "    sections_of_interest = [\"Abstract\", \"Introduction\", \"Discussion\", \"Conclusion\"]\n",
    "\n",
    "    # Define keyword groups\n",
    "    keywords = [\n",
    "    [\"Novelty\", \"novel\"],\n",
    "    [\"Simplicity\", \"simple\"],\n",
    "    [\"Generalization\", \"generalisable\"],\n",
    "    [\"Flexibility/Extensibility\", \"flexible\", \"flexibility\", \"extensibility\", \"extensible\"],\n",
    "    [\"Robustness\", \"robust\"],\n",
    "    [\"Realistic output\", \"realistic\"],\n",
    "    [\"Formal description/analysis\", \"formal\", \"mathematical\"],\n",
    "    [\"Theoretical guarantees\", \"guarantee\"],\n",
    "    [\"Approximation\", \"approximate\"],\n",
    "    [\"Quantitative evidence (e.g. experiments)\", \"experiment\"],\n",
    "    [\"Qualitative evidence (e.g. examples)\", \"example\"],\n",
    "    [\"Scientific methodology\", \"scientific\"],\n",
    "    [\"Controllability (of model owner)\", \"control\"],\n",
    "    [\"Human-like mechanism\", \"human\"],\n",
    "    [\"Low cost\", \"cheap\", \"cost\"],\n",
    "    [\"Large scale\", \"scale\"],\n",
    "    [\"Promising\"],\n",
    "    [\"Generality\", \"general\"],\n",
    "    [\"Principled\", \"principles\"],\n",
    "    [\"Exactness\", \"exact\"],\n",
    "    [\"Preciseness\", \"precise\"],\n",
    "    [\"Concreteness\", \"correct\"],\n",
    "    [\"Automatic\", \"automated\"],\n",
    "    [\"Performance\"],\n",
    "    [\"Accuracy\"],\n",
    "    [\"Avoiding train/test discrepancy\", \"train/test\", \"discrepancy\"],\n",
    "    [\"State-of-the-art\"],\n",
    "    [\"Efficiency\", \"efficient\"],\n",
    "    [\"Reduced training time\", \"training time\"],\n",
    "    [\"Memory efficiency\"],\n",
    "    [\"Data efficiency\"],\n",
    "    [\"Label efficiency (reduced need for labeled data)\"],\n",
    "    [\"Energy efficiency\"],\n",
    "    [\"Effectiveness\", \"effective\"],\n",
    "    [\"Successful\"],\n",
    "    [\"Building on classic work\", \"classic work\"],\n",
    "    [\"Building in recent work\", \"recent work\"],\n",
    "    [\"Unifying ideas or integrating components\", \"unifying\"],\n",
    "    [\"Identifying limitations\", \"limitations\"],\n",
    "    [\"Critique\", \"criticism\"],\n",
    "    [\"Understanding (for researchers)\", \"understanding\"],\n",
    "    [\"Improvement\"],\n",
    "    [\"Progress\"],\n",
    "    [\"Used in practice/Popular\", \"practice\", \"popular\"],\n",
    "    [\"Reproducibility\", \"reproduce\"],\n",
    "    [\"Easy to implement\", \"implement\"],\n",
    "    [\"Requires few resources\", \"resources\"],\n",
    "    [\"Parallelizability / distributed\", \"parallelizability\", \"parallelization\", \"distributed\"],\n",
    "    [\"Facilitating use (e.g. sharing code)\", \"sharing code\"],\n",
    "    [\"Scales up\", \"scale up\"],\n",
    "    [\"Applies to real world\", \"real world\"],\n",
    "    [\"Learning from humans\"],\n",
    "    [\"Practical\", \"practice\"],\n",
    "    [\"Useful\", \"usefulness\"],\n",
    "    [\"Interpretable (to users)\", \"interpretable\"],\n",
    "    [\"Transparent (to users)\", \"transparent\", \"transparency\"],\n",
    "    [\"Privacy\", \"privacy\", \"private\"],\n",
    "    [\"Fairness\", \"fair\"],\n",
    "    [\"Not socially biased\", \"social bias\", \"socially bias\", \"social\", \"society\"],\n",
    "    [\"User influence\", \"user\"],\n",
    "    [\"Collective influence\", \"collective\"],\n",
    "    [\"Deferral to humans\"],\n",
    "    [\"Critiqability\", \"criticism\"],\n",
    "    [\"Beneficence\", \"beneficable\"],\n",
    "    [\"Non-maleficence\"],\n",
    "    [\"Justice\"],\n",
    "    [\"Respect for Persons\"],\n",
    "    [\"Autonomy (power to decide)\", \"autonomy\", \"autonome\"],\n",
    "    [\"Explicability\", \"explicable\"],\n",
    "    [\"Respect for Law and public interest\", \"respect for law\", \"respect for public interest\"],\n",
    "    [\"Security\", \"secure\"],\n",
    "    [\"Easy to work with\"],\n",
    "    [\"Realistic world model\", \"world model\"],\n",
    "    [\"Fast\", \"speed\"]\n",
    "    ]\n",
    "\n",
    "\n",
    "    # Process papers and save results\n",
    "    keyword_matrix_neurips, sentences_neurips = process_papers(\"Paper Neurips\", sections_of_interest, keywords)\n",
    "    keyword_matrix_icml, sentences_icml = process_papers(\"Paper ICML\", sections_of_interest, keywords)\n",
    "    \n",
    "    keyword_matrix_neurips.to_csv(\"keyword_counts_neurips.csv\", index=False)\n",
    "    print(f\"Keyword counts saved to keyword_counts_neurips.csv\")\n",
    "    \n",
    "    keyword_matrix_icml.to_csv(\"keyword_counts_icml.csv\", index=False)\n",
    "    print(f\"Keyword counts saved to keyword_counts_icml.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print sentences containing keyword occurrences\n",
    "# for key, sentences in sentences_neurips.items():\n",
    "#     print(f\"\\nSentences containing '{key}' in NeurIPS papers:\")\n",
    "#     for sentence in sentences:\n",
    "#         print(f\"- {sentence}\")\n",
    "        \n",
    "# for key, sentences in sentences_icml.items():\n",
    "#     print(f\"\\nSentences containing '{key}' in ICML papers:\")\n",
    "#     for sentence in sentences:\n",
    "#         print(f\"- {sentence}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
